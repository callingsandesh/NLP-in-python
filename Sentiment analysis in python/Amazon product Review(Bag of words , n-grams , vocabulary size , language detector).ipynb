{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a506d7d",
   "metadata": {},
   "source": [
    "## BAG OF WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "449293da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0 1 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 0 1 1 1 1 2 1]]\n"
     ]
    }
   ],
   "source": [
    "# Import the required function\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "annak = ['Happy families are all alike;', 'every unhappy family is unhappy in its own way']\n",
    "\n",
    "# Build the vectorizer and fit it\n",
    "anna_vect = CountVectorizer()\n",
    "anna_vect.fit(annak)\n",
    "\n",
    "# Create the bow representation\n",
    "anna_bow = anna_vect.transform(annak)\n",
    "\n",
    "# Print the bag-of-words result \n",
    "print(anna_bow.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea41e30",
   "metadata": {},
   "source": [
    "## BOW using product reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f04456",
   "metadata": {},
   "source": [
    "Now we will apply BOW to the amazon review of products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4be341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "reviews = pd.read_csv('amazon_reviews_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "320aae4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite musi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Excellent Soundtrack: I truly like this sound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After H...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  score                                             review\n",
       "0           0      1   Stuning even for the non-gamer: This sound tr...\n",
       "1           1      1   The best soundtrack ever to anything.: I'm re...\n",
       "2           2      1   Amazing!: This soundtrack is my favorite musi...\n",
       "3           3      1   Excellent Soundtrack: I truly like this sound...\n",
       "4           4      1   Remember, Pull Your Jaw Off The Floor After H..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "180a4f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e7b8e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>after</th>\n",
       "      <th>all</th>\n",
       "      <th>also</th>\n",
       "      <th>am</th>\n",
       "      <th>an</th>\n",
       "      <th>and</th>\n",
       "      <th>any</th>\n",
       "      <th>are</th>\n",
       "      <th>as</th>\n",
       "      <th>...</th>\n",
       "      <th>what</th>\n",
       "      <th>when</th>\n",
       "      <th>which</th>\n",
       "      <th>who</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>work</th>\n",
       "      <th>would</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   about  after  all  also  am  an  and  any  are  as  ...  what  when  which  \\\n",
       "0      0      0    1     0   0   0    2    0    0   0  ...     0     0      0   \n",
       "1      0      0    0     0   0   0    3    1    1   0  ...     0     0      0   \n",
       "2      0      0    3     0   0   1    4    0    1   1  ...     0     0      1   \n",
       "3      0      0    0     0   0   0    9    0    1   0  ...     0     0      0   \n",
       "4      0      1    0     0   0   0    3    0    1   0  ...     0     0      0   \n",
       "\n",
       "   who  will  with  work  would  you  your  \n",
       "0    2     0     1     0      2    0     1  \n",
       "1    0     0     0     0      1    1     0  \n",
       "2    1     0     0     1      1    2     0  \n",
       "3    0     0     0     0      0    0     0  \n",
       "4    0     0     0     0      0    3     1  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "# Build the vectorizer, specify max features \n",
    "vect = CountVectorizer(max_features=100)\n",
    "# Fit the vectorizer\n",
    "vect.fit(reviews.review)\n",
    "\n",
    "# Transform the review column\n",
    "X_review = vect.transform(reviews.review)\n",
    "\n",
    "# Create the bow representation\n",
    "X_df=pd.DataFrame(X_review.toarray(), columns=vect.get_feature_names())\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df588d5",
   "metadata": {},
   "source": [
    "We have successfully built  BOW generated vocabulary and transformed it to numeric features of the dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b5ac49",
   "metadata": {},
   "source": [
    "## Specifying token sequence length with BOW\n",
    "We can specify different length of tokens - what we called n-grams - we can better capture the context, which can be very important.\n",
    "\n",
    "For this we will just take the 100 sample of reviews of amazon product since all of the data can occupy very large amount of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2237be36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10  10 95  10 cups  100  100 years  110  110 years  114622  \\\n",
      "0   0      0        0    0          0    0          0       0   \n",
      "1   0      0        0    0          0    0          0       0   \n",
      "2   0      0        0    0          0    0          0       0   \n",
      "3   0      0        0    0          0    0          0       0   \n",
      "4   0      0        0    0          0    0          0       0   \n",
      "\n",
      "   114622 excellent  12  ...  youtube video  yr  yr old  yucky  yucky thick  \\\n",
      "0                 0   0  ...              0   0       0      0            0   \n",
      "1                 0   0  ...              0   0       0      0            0   \n",
      "2                 0   0  ...              0   0       0      0            0   \n",
      "3                 0   0  ...              0   0       0      0            0   \n",
      "4                 0   0  ...              0   0       0      0            0   \n",
      "\n",
      "   zelbessdisk  zelbessdisk three  zen  zen baseball  zen motorcycle  \n",
      "0            0                  0    0             0               0  \n",
      "1            0                  0    0             0               0  \n",
      "2            0                  0    0             0               0  \n",
      "3            1                  1    0             0               0  \n",
      "4            0                  0    0             0               0  \n",
      "\n",
      "[5 rows x 8436 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "# Build the vectorizer, specify token sequence and fit\n",
    "vect = CountVectorizer(ngram_range=(1,2))\n",
    "vect.fit(reviews[:100].review)\n",
    "\n",
    "# Transform the review column\n",
    "X_review = vect.transform(reviews[:100].review)\n",
    "\n",
    "# Create the bow representation\n",
    "X_df = pd.DataFrame(X_review.toarray(), columns=vect.get_feature_names())\n",
    "print(X_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ae913c",
   "metadata": {},
   "source": [
    "We have built a numeric representation of the review column using uni- and bigrams!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d337396",
   "metadata": {},
   "source": [
    "## BOW with n-grams and vocabulary size\n",
    "We will build a bag-of-words once more, using the reviews dataset of Amazon product reviews. We will be to limit the size of the vocabulary and specify the length of the token sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9bea9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   able to  about how  about it  about the  about this  after reading  \\\n",
      "0        0          0         0          0           0              0   \n",
      "1        0          0         0          0           0              0   \n",
      "2        0          0         0          0           0              0   \n",
      "3        0          0         0          0           0              0   \n",
      "4        0          0         0          0           0              0   \n",
      "\n",
      "   after the  again and  ago and  agree with  ...  you think  you to  you ve  \\\n",
      "0          0          0        0           0  ...          0       0       0   \n",
      "1          0          0        0           0  ...          0       0       0   \n",
      "2          0          0        0           0  ...          0       0       2   \n",
      "3          0          0        0           0  ...          0       0       0   \n",
      "4          0          0        0           0  ...          0       0       1   \n",
      "\n",
      "   you want  you will  you won  you would  your money  your own  your time  \n",
      "0         0         0        0          0           0         0          0  \n",
      "1         0         0        0          0           0         0          0  \n",
      "2         0         0        0          0           0         0          0  \n",
      "3         0         0        0          0           0         0          0  \n",
      "4         0         0        0          0           0         0          0  \n",
      "\n",
      "[5 rows x 1000 columns]\n"
     ]
    }
   ],
   "source": [
    "#Import the vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Build the vectorizer, specify max features and fit\n",
    "vect = CountVectorizer(max_features=1000, ngram_range=(2, 2), max_df=500)\n",
    "vect.fit(reviews.review)\n",
    "\n",
    "# Transform the review\n",
    "X_review = vect.transform(reviews.review)\n",
    "\n",
    "# Create a DataFrame from the bow representation\n",
    "X_df = pd.DataFrame(X_review.toarray(), columns=vect.get_feature_names())\n",
    "print(X_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c157cba4",
   "metadata": {},
   "source": [
    "## Language detection of product reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c17dbb8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'non_english_reviews' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-9365eb4c2651>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Assign the list to a new feature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mnon_english_reviews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'language'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlanguages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnon_english_reviews\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'non_english_reviews' is not defined"
     ]
    }
   ],
   "source": [
    "from langdetect import detect_langs\n",
    "languages = [] \n",
    "\n",
    "# Loop over the rows of the dataset and append  \n",
    "for row in range(len(reviews.review)):\n",
    "    languages.append(detect_langs(reviews.iloc[row, 2]))\n",
    "\n",
    "# Clean the list by splitting     \n",
    "languages = [str(lang).split(':')[0][1:] for lang in languages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba340819",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>169</td>\n",
       "      <td>1</td>\n",
       "      <td>Awesume! BEST BLOCKS EVER!: THIS TOY WAS OUR ...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>1249</td>\n",
       "      <td>1</td>\n",
       "      <td>Il grande ritorno!: E' dai tempi del tour di ...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>1259</td>\n",
       "      <td>1</td>\n",
       "      <td>La reencarnación vista por un científico: El ...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>1261</td>\n",
       "      <td>1</td>\n",
       "      <td>Magnifico libro: Brian Weiss ha dejado una ma...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>1639</td>\n",
       "      <td>1</td>\n",
       "      <td>El libro mas completo que existe para nosotra...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>1745</td>\n",
       "      <td>1</td>\n",
       "      <td>Excelente!: Una excelente guía para todos aqu...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2316</th>\n",
       "      <td>2316</td>\n",
       "      <td>1</td>\n",
       "      <td>Nightwish is unique and rocks for eva: Moi to...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>2486</td>\n",
       "      <td>1</td>\n",
       "      <td>Palabras de aliento para tu caminar con Dios:...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>2760</td>\n",
       "      <td>0</td>\n",
       "      <td>Completement nul: Fait sur commande et ennuya...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>2903</td>\n",
       "      <td>1</td>\n",
       "      <td>fabuloso: mil gracias por el producto fabulos...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>2908</td>\n",
       "      <td>0</td>\n",
       "      <td>Geh: Blah blah, sexy girl, blah blah, fightin...</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3318</th>\n",
       "      <td>3318</td>\n",
       "      <td>1</td>\n",
       "      <td>Excelentes botas.. excelentes boots: Excelent...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3694</th>\n",
       "      <td>3694</td>\n",
       "      <td>0</td>\n",
       "      <td>Why not Spanish ???: Alguien me puede decir p...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144</th>\n",
       "      <td>4144</td>\n",
       "      <td>0</td>\n",
       "      <td>LEAKED FIRST DAY FOR MY GUEST: IT HAD A LEAK ...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4820</th>\n",
       "      <td>4820</td>\n",
       "      <td>1</td>\n",
       "      <td>La mejor película de Moore: A mi juicio, esta...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4914</th>\n",
       "      <td>4914</td>\n",
       "      <td>0</td>\n",
       "      <td>De la poudre aux yeux: J'ai acheté un Sansa V...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5720</th>\n",
       "      <td>5720</td>\n",
       "      <td>1</td>\n",
       "      <td>C'est magnifique! il y a du vrai dans ce qui'...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875</th>\n",
       "      <td>5875</td>\n",
       "      <td>1</td>\n",
       "      <td>Erreur: \"Les Triplettes de Belleville\" n'a pa...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5901</th>\n",
       "      <td>5901</td>\n",
       "      <td>1</td>\n",
       "      <td>Buen cargador: Product very good, I am of Ven...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6234</th>\n",
       "      <td>6234</td>\n",
       "      <td>1</td>\n",
       "      <td>5+ stars. LO MEJOR DE LO QUE HE LEIDO EN MI V...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6631</th>\n",
       "      <td>6631</td>\n",
       "      <td>0</td>\n",
       "      <td>certains bugs viennent tout gacher: le jeu es...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7078</th>\n",
       "      <td>7078</td>\n",
       "      <td>1</td>\n",
       "      <td>Variedad: Bueno tener este album debido a su ...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7888</th>\n",
       "      <td>7888</td>\n",
       "      <td>0</td>\n",
       "      <td>Ich weiß ja nicht !: Also ich finde es ja tol...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7983</th>\n",
       "      <td>7983</td>\n",
       "      <td>1</td>\n",
       "      <td>1F4T: Cet album est chanté vraiment bien. Jea...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8018</th>\n",
       "      <td>8018</td>\n",
       "      <td>1</td>\n",
       "      <td>Exelente eleccion: Los mejores zapatos de fut...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8340</th>\n",
       "      <td>8340</td>\n",
       "      <td>1</td>\n",
       "      <td>Jean de Florette et Manon des sources: bien a...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9265</th>\n",
       "      <td>9265</td>\n",
       "      <td>1</td>\n",
       "      <td>Excelente: Manu es una de los mejores cantant...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9422</th>\n",
       "      <td>9422</td>\n",
       "      <td>0</td>\n",
       "      <td>DVD CON PROBLEMAS: ESTE DVD LLEGO EN BUEN TIE...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9624</th>\n",
       "      <td>9624</td>\n",
       "      <td>0</td>\n",
       "      <td>baaaaaadddddddd bookkkkkkk: por favor no gast...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  score                                             review  \\\n",
       "169          169      1   Awesume! BEST BLOCKS EVER!: THIS TOY WAS OUR ...   \n",
       "1249        1249      1   Il grande ritorno!: E' dai tempi del tour di ...   \n",
       "1259        1259      1   La reencarnación vista por un científico: El ...   \n",
       "1261        1261      1   Magnifico libro: Brian Weiss ha dejado una ma...   \n",
       "1639        1639      1   El libro mas completo que existe para nosotra...   \n",
       "1745        1745      1   Excelente!: Una excelente guía para todos aqu...   \n",
       "2316        2316      1   Nightwish is unique and rocks for eva: Moi to...   \n",
       "2486        2486      1   Palabras de aliento para tu caminar con Dios:...   \n",
       "2760        2760      0   Completement nul: Fait sur commande et ennuya...   \n",
       "2903        2903      1   fabuloso: mil gracias por el producto fabulos...   \n",
       "2908        2908      0   Geh: Blah blah, sexy girl, blah blah, fightin...   \n",
       "3318        3318      1   Excelentes botas.. excelentes boots: Excelent...   \n",
       "3694        3694      0   Why not Spanish ???: Alguien me puede decir p...   \n",
       "4144        4144      0   LEAKED FIRST DAY FOR MY GUEST: IT HAD A LEAK ...   \n",
       "4820        4820      1   La mejor película de Moore: A mi juicio, esta...   \n",
       "4914        4914      0   De la poudre aux yeux: J'ai acheté un Sansa V...   \n",
       "5720        5720      1   C'est magnifique! il y a du vrai dans ce qui'...   \n",
       "5875        5875      1   Erreur: \"Les Triplettes de Belleville\" n'a pa...   \n",
       "5901        5901      1   Buen cargador: Product very good, I am of Ven...   \n",
       "6234        6234      1   5+ stars. LO MEJOR DE LO QUE HE LEIDO EN MI V...   \n",
       "6631        6631      0   certains bugs viennent tout gacher: le jeu es...   \n",
       "7078        7078      1   Variedad: Bueno tener este album debido a su ...   \n",
       "7888        7888      0   Ich weiß ja nicht !: Also ich finde es ja tol...   \n",
       "7983        7983      1   1F4T: Cet album est chanté vraiment bien. Jea...   \n",
       "8018        8018      1   Exelente eleccion: Los mejores zapatos de fut...   \n",
       "8340        8340      1   Jean de Florette et Manon des sources: bien a...   \n",
       "9265        9265      1   Excelente: Manu es una de los mejores cantant...   \n",
       "9422        9422      0   DVD CON PROBLEMAS: ESTE DVD LLEGO EN BUEN TIE...   \n",
       "9624        9624      0   baaaaaadddddddd bookkkkkkk: por favor no gast...   \n",
       "\n",
       "     language  \n",
       "169        de  \n",
       "1249       it  \n",
       "1259       es  \n",
       "1261       es  \n",
       "1639       es  \n",
       "1745       es  \n",
       "2316       fr  \n",
       "2486       es  \n",
       "2760       fr  \n",
       "2903       es  \n",
       "2908       id  \n",
       "3318       es  \n",
       "3694       es  \n",
       "4144       de  \n",
       "4820       es  \n",
       "4914       fr  \n",
       "5720       fr  \n",
       "5875       fr  \n",
       "5901       es  \n",
       "6234       es  \n",
       "6631       fr  \n",
       "7078       es  \n",
       "7888       de  \n",
       "7983       fr  \n",
       "8018       es  \n",
       "8340       fr  \n",
       "9265       es  \n",
       "9422       de  \n",
       "9624       es  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign the list to a new feature \n",
    "reviews['language'] = languages\n",
    "\n",
    "reviews[reviews['language'] != 'en']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
